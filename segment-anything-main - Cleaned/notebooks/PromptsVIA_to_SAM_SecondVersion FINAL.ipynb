{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment prompts from VGG to sam\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import json\n",
    "from skimage.measure import label, regionprops\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(),'..'))\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n",
    "\n",
    "\n",
    "def prepare_image(image, transform):\n",
    "    image = transform.apply_image(image)\n",
    "    image = torch.as_tensor(image) \n",
    "    return image.permute(2, 0, 1).contiguous()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "def get_background_points(image, bbox, binary_mask):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    \n",
    "\n",
    "    # Extract foreground and background coordinates\n",
    "    fg_coords = np.argwhere(binary_mask == 255)\n",
    "    bg_coords = np.argwhere(binary_mask == 0)\n",
    "\n",
    "    # Points inside the bounding box but outside the foreground\n",
    "    inside_bbox_outside_fg = [\n",
    "        (i, j) for i, j in bg_coords if x_min <= j <= x_max and y_min <= i <= y_max\n",
    "    ]\n",
    "\n",
    "    # Points just outside the bounding box\n",
    "    outside_bbox = [\n",
    "        (i, j) for i, j in bg_coords if\n",
    "        (x_min - 1 <= j <= x_max + 1 and (i < y_min or i > y_max)) or\n",
    "        (y_min - 1 <= i <= y_max + 1 and (j < x_min or j > x_max))\n",
    "    ]\n",
    "\n",
    "    # Convert image to grayscale to find zero-pixel points\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    zero_pixel_coords = np.argwhere(grayscale_image == 0)\n",
    "\n",
    "    # Randomly sample the points\n",
    "    random_points = []\n",
    "\n",
    "    if inside_bbox_outside_fg:\n",
    "        random_points.append(random.choice(inside_bbox_outside_fg))\n",
    "\n",
    "    if outside_bbox:\n",
    "        random_points.append(random.choice(outside_bbox))\n",
    "\n",
    "    if zero_pixel_coords.any():\n",
    "        random_points.append(tuple(random.choice(zero_pixel_coords)))\n",
    "\n",
    "    # Randomly add remaining points from the background\n",
    "    random_points_set = set(random_points)\n",
    "    bg_coords_set = set(tuple(map(tuple, bg_coords)))\n",
    "    remaining_bg_points = list(bg_coords_set - random_points_set)\n",
    "\n",
    "    while len(random_points) < 5 and remaining_bg_points:\n",
    "        random_points.append(random.choice(remaining_bg_points))\n",
    "\n",
    "    # Limit to a maximum of 5 points\n",
    "    return random_points[:5]\n",
    "\n",
    "def reduce_bbox(bbox, percentage, center_point):\n",
    "    \"\"\"\n",
    "    Reduces the size of the bounding box according to the given percentage, centered at the specified point.\n",
    "    \n",
    "    :param bbox: The bounding box in the format (xmin, ymin, xmax, ymax).\n",
    "    :param percentage: The percentage by which to reduce the size of the bounding box.\n",
    "    :param center_point: The point (x, y) around which to center the reduced bounding box.\n",
    "    :return: The reduced bounding box in the format (xmin, ymin, xmax, ymax) as integers.\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    center_x, center_y = center_point\n",
    "\n",
    "    # Calculate the current width and height of the bbox\n",
    "    current_width = x_max - x_min\n",
    "    current_height = y_max - y_min\n",
    "\n",
    "    # Calculate the new width and height based on the percentage\n",
    "    new_area = (current_width * current_height) * (percentage)\n",
    "    new_width = (new_area * current_width / current_height) ** 0.5\n",
    "    new_height = (new_area * current_height / current_width) ** 0.5\n",
    "\n",
    "    # Ensure the new bbox is centered around the given center_point\n",
    "    new_x_min = center_x - new_width / 2\n",
    "    new_x_max = center_x + new_width / 2\n",
    "    new_y_min = center_y - new_height / 2\n",
    "    new_y_max = center_y + new_height / 2\n",
    "\n",
    "    return (int(new_x_min), int(new_y_min), int(new_x_max), int(new_y_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = cv2.imread('C:\\\\Users\\\\d42684\\\\Documents\\\\STAGE\\\\CODES\\\\ACtoolbox-main\\\\Dataset\\\\Small_ARIS_Mauzac\\\\TEST\\\\All_Originals\\\\2014-11-16_002000_t8_Obj_frame3065.jpg')\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#2014-11-05_184000_t0_Obj_frame315.jpg\n",
    "#2014-11-16_002000_t0_Obj_frame508.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(image)\n",
    "# plt.axis('on')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "sam_checkpoint = r\"C:\\Users\\chapi\\Documents\\STAGE\\CODE\\segment-anything-main\\sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "#sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageList = glob.glob(os.path.join(r'C:\\Users\\chapi\\Documents\\STAGE\\CODE\\bgslibrary\\SELECTED ORIGINAL IMAGES\\*.jpg'))\n",
    "MaskImageList = glob.glob(os.path.join(r'C:\\Users\\chapi\\Documents\\STAGE\\CODE\\bgslibrary\\SELECTED ORIGINAL IMAGES\\*.png'))\n",
    "#C:\\Users\\d42684\\Documents\\STAGE\\CODES\\ACtoolbox-main\\Dataset\\Small_ARIS_SELUNE\\2019-05-02_005000.avi\\False Negatives\\SIL_1\n",
    "#ImageList = glob.glob(os.path.join('C:\\\\Users\\\\d42684\\\\Documents\\\\STAGE\\\\CODES\\\\ACtoolbox-main\\\\Dataset\\\\Small_ARIS_Mauzac\\\\TEST\\\\All_Originals\\\\*.jpg'))\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\chapi\\Documents\\STAGE\\CODE\\bgslibrary\\ACtoolbox-main\\SecondVersion_Annotations_Filled.csv\").iloc[11761:] ## Ddoesn't take into account videos with masks already generated\n",
    "\n",
    "#df = pd.read_csv(r'C:\\Users\\chapi\\Documents\\STAGE\\CODE\\segment-anything-main\\notebooks\\SecondVersion_Annotations_Filled.csv')\n",
    "#C:\\Users\\chapi\\Documents\\STAGE\\CODE\\bgslibrary\\updateddf.csv\n",
    "filtered_df0 = df[df['file_attributes'] != '{\"Object_Count\":\"0\"}']\n",
    "\n",
    "for i in range(len(ImageList)): # Puedo optimizar al directamente eliminar todos los que tienen region 0\n",
    "\n",
    "    imageName = ImageList[i].split('\\\\')[-1]\n",
    "\n",
    "\n",
    "    filtered_df = filtered_df0[filtered_df0['filename'] == imageName]\n",
    "\n",
    "    # Check if filtered_df is empty\n",
    "    if filtered_df.empty:\n",
    "        continue  # Skip this iteration if no matches found\n",
    "\n",
    "\n",
    "\n",
    "    print(\"File attributes (regions):\")\n",
    "    print(json.loads(filtered_df.iloc[0]['file_attributes'])['Object_Count'])\n",
    "\n",
    "\n",
    "    MaskImage = cv2.imread(MaskImageList[i])\n",
    "    MaskImage = cv2.cvtColor(MaskImage, cv2.COLOR_BGR2GRAY)\n",
    "    print(np.unique(MaskImage))\n",
    "    image = cv2.imread(ImageList[i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    predictor.set_image(image)\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"image atributes: \")\n",
    "    print(imageName)\n",
    "    print(filtered_df[\"region_shape_attributes\"])\n",
    "    print('-----------------------------------------')\n",
    "\n",
    "    cx = []\n",
    "    cy = []\n",
    "\n",
    "    x0 = []\n",
    "    y0 = []\n",
    "    y1 = []\n",
    "    x1 = []\n",
    "    classname = []\n",
    "    for i in range(len(filtered_df)):\n",
    "\n",
    "        info = json.loads(filtered_df.iloc[i]['region_shape_attributes'])\n",
    "        class_info = json.loads(filtered_df.iloc[i]['region_attributes'])\n",
    "        if info['name'] == 'point':\n",
    "\n",
    "            cx.append(info['cx'])\n",
    "            cy.append(info['cy'])\n",
    "            #print(f\"Point - cx: {cx}, cy: {cy}\")\n",
    "\n",
    "        elif info['name'] == 'rect':\n",
    "            # Process rectangle information\n",
    "            x0.append(info['x'])\n",
    "            y0.append(info['y'])\n",
    "            x1.append(int(info['x']) + int(info['width']))\n",
    "            y1.append(int(info['y']) + int(info['height']))\n",
    "            classname.append(class_info[\"Object\"])\n",
    "            print(class_info[\"Object\"])\n",
    "            #print(f\"Rectangle - x: {x0}, y: {y0}, x1: {x1}, y1: {y1}\")\n",
    "            #print('wait')\n",
    "    \n",
    "    \n",
    "    Points_array = np.column_stack((np.array(cx), np.array(cy)))\n",
    "    Bbox_array = np.column_stack((x0, y0, x1, y1))\n",
    "\n",
    "    print(np.column_stack((x0, y0, x1, y1)))\n",
    "\n",
    "\n",
    "    ### Set up the loop for several objects using bbox to separate points\n",
    "    Objects = 0\n",
    "    mixed = np.zeros((image.shape[0],image.shape[1]))\n",
    "    for bbox in Bbox_array:\n",
    "\n",
    "        # Se hacen predicciones individuales para casos en los que haya mas de un objeto  de interes en la imagen, mayormente para los casos smallfish\n",
    "        SingleObject_Points = []\n",
    "        for point in Points_array:\n",
    "             # para los small fish, como la manera en la que se guarda el bbox y su medoid, no dice a cual corresponde, toca limitarlos para podeer asignarlos correctamente\n",
    "            x, y = point\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "            if x_min <= x <= x_max and y_min <= y <= y_max:\n",
    "                SingleObject_Points.append((x,y))\n",
    "\n",
    "        \n",
    "        bg_points = get_background_points(image, reduce_bbox(tuple(bbox),0.2, SingleObject_Points[0]), MaskImage)\n",
    "\n",
    "        input_points = np.array([np.array(SingleObject_Points[0]),np.array(bg_points[0][::-1]),np.array(bg_points[1][::-1]),np.array(bg_points[2][::-1]),\n",
    "                                 np.array(bg_points[3][::-1]),np.array(bg_points[4][::-1])])\n",
    "\n",
    "        fg_label = np.ones(len(SingleObject_Points))\n",
    "        bg_label = np.zeros(len(bg_points))\n",
    "\n",
    "        input_label = np.concatenate((fg_label,bg_label))\n",
    "\n",
    "        print(imageName)\n",
    "\n",
    "        masks, scores, logits = predictor.predict(\n",
    "        point_coords=input_points,\n",
    "        point_labels=input_label,\n",
    "        box=bbox,\n",
    "        multimask_output=True,)\n",
    "        \n",
    "        \n",
    "        mask_input = logits[np.argmax(scores), :, :]  # Choose the model's best mask\n",
    "\n",
    "        mask, score, _ = predictor.predict(\n",
    "        point_coords=input_points,\n",
    "        point_labels=input_label,\n",
    "        box=bbox,\n",
    "        mask_input=mask_input[None, :, :],\n",
    "        multimask_output=False,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        mixed = squeezed_array = np.squeeze(mask.astype(int), axis=0)*255 + mixed\n",
    "        print(np.unique(squeezed_array))\n",
    "        #_, squeezed_array = cv2.threshold(squeezed_array, 127, 255, cv2.THRESH_BINARY)\n",
    "        mixed =  np.where(mixed != 0, 255, 0)\n",
    "\n",
    "    plt.imshow(mixed, cmap=\"gray\")\n",
    "    plt.show()\n",
    "            \n",
    "        #mask_image = Image.fromarray(mask_image)\n",
    "\n",
    "    os.makedirs(os.path.join(r'C:\\Users\\chapi\\Documents\\STAGE\\CODE\\bgslibrary\\ACtoolbox-main\\Dataset\\Small_ARIS_Mauzac\\TEST\\All_Originals\\NewMasks3' ),exist_ok = True)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(r'C:\\Users\\chapi\\Documents\\STAGE\\CODE\\bgslibrary\\ACtoolbox-main\\Dataset\\Small_ARIS_Mauzac\\TEST\\All_Originals\\NewMasks3', str('m_'+str(classname[Objects])+\"_\"+imageName)), mixed)\n",
    "\n",
    "        #cv2.imwrite(os.path.join(r'C:\\Users\\d42684\\Documents\\STAGE\\CODES\\ACtoolbox-main\\Dataset\\Small_ARIS_SELUNE\\2019-05-02_005000.avi\\False Negatives\\SIL_1\\masks_bbox',str('m_'+imageName)), masks*255)\n",
    "        #r'C:\\Users\\d42684\\Documents\\STAGE\\CODES\\ACtoolbox-main\\Dataset\\Small_ARIS_SELUNE\\2019-05-02_005000.avi\\False Negatives\\SIL_1\\\n",
    "\n",
    "        #mask_image.save(os.path.join(r'C:\\Users\\d42684\\Documents\\STAGE\\CODES\\ACtoolbox-main\\Dataset\\Small_ARIS_Mauzac\\TEST\\All_Originals\\masks_bbox',str('m_'+imageName)))\n",
    "        # for box in Bbox_array:\n",
    "        #     show_box(box.numpy(), plt.gca())\n",
    "        #plt.axis('off')\n",
    "\n",
    "\n",
    "        #plt.tight_layout()\n",
    "        #plt.show()\n",
    "        # masks, scores, logits = predictor.predict(\n",
    "        #     point_coords=input_point,\n",
    "        #     point_labels=input_label,\n",
    "        #     multimask_output=True,   \n",
    "        # )\n",
    "    #Objects =  Objects + 1\n",
    "    #print(\"wait\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
